{"cells":[{"cell_type":"code","execution_count":1,"id":"4fe8db40","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyspark in /usr/lib/spark/python (3.1.3)\n","Collecting py4j==0.10.9 (from pyspark)\n","  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n","\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m198.6/198.6 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n","\u001B[?25hInstalling collected packages: py4j\n","  Attempting uninstall: py4j\n","    Found existing installation: py4j 0.10.9.7\n","    Uninstalling py4j-0.10.9.7:\n","      Successfully uninstalled py4j-0.10.9.7\n","Successfully installed py4j-0.10.9\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install pyspark"]},{"cell_type":"code","execution_count":2,"id":"797cac11","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: py4j in /opt/conda/miniconda3/lib/python3.8/site-packages (0.10.9)\n","Collecting py4j\n","  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n","Installing collected packages: py4j\n","  Attempting uninstall: py4j\n","    Found existing installation: py4j 0.10.9\n","    Uninstalling py4j-0.10.9:\n","      Successfully uninstalled py4j-0.10.9\n","\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pyspark 3.1.3 requires py4j==0.10.9, but you have py4j 0.10.9.7 which is incompatible.\u001B[0m\u001B[31m\n","\u001B[0mSuccessfully installed py4j-0.10.9.7\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install --upgrade py4j"]},{"cell_type":"code","execution_count":3,"id":"be2745e6","metadata":{},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType,StructField, StringType, IntegerType \n","from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n","from pyspark.sql.functions import col,array_contains\n","from pyspark.sql import SQLContext \n","from pyspark.ml.recommendation import ALS\n","from pyspark.sql.functions import udf,col,when\n","from pyspark.sql.functions import to_timestamp,date_format\n","import numpy as np\n","import pandas as pd\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *\n","from pyspark.sql.window import *\n","\n","sc = SparkSession.builder.appName(\"Recommendations\").config(\"spark.sql.files.maxPartitionBytes\", 5000000).getOrCreate()\n","spark = SparkSession(sc)\n","\n"]},{"cell_type":"code","execution_count":4,"id":"ef705f98","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["root\n"," |-- t_dat: string (nullable = true)\n"," |-- customer_id: string (nullable = true)\n"," |-- article_id: string (nullable = true)\n"," |-- price: string (nullable = true)\n"," |-- sales_channel_id: string (nullable = true)\n","\n"]}],"source":["transaction = spark.read.option(\"header\",True) \\\n","              .csv(\"gs://hnmt/transactions.csv\")\n","transaction.printSchema()"]},{"cell_type":"code","execution_count":5,"id":"b5395ad1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["('2018-09-20', '2020-09-22')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from pyspark.sql.functions import min, max\n","from pyspark.sql.functions import unix_timestamp, lit\n","min_date, max_date = transaction.select(min(\"t_dat\"), max(\"t_dat\")).first()\n","min_date, max_date"]},{"cell_type":"markdown","id":"6f3dfb21","metadata":{},"source":["In this transaction dataset we have 31,788,324 rows and 5 columns.Let's capture first what are the most recently bought articles.For recommendation I am selecting only date 2020-09-22 which is the last transaction date.</h1>"]},{"cell_type":"code","execution_count":6,"id":"725793de","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 4:=======================================================> (33 + 1) / 34]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------+----------+-----+\n","|         customer_id|article_id|count|\n","+--------------------+----------+-----+\n","|82be633d4ca5ea541...| 927172004|    1|\n","|3ec69c320b6aced81...| 631536021|    1|\n","|a2be13b3998897084...| 828991003|    1|\n","|1b2867a6205a7a528...| 894788003|    1|\n","|d2f89ce024ac8d4fb...| 849738002|    1|\n","+--------------------+----------+-----+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["\n","hm =  transaction.withColumn('t_dat', transaction['t_dat'].cast('string'))\n","hm = hm.withColumn('date', from_unixtime(unix_timestamp('t_dat', 'yyyy-MM-dd')))\n","hm = hm.withColumn('year', year(col('date')))\n","hm = hm.withColumn('month', month(col('date')))\n","hm = hm.withColumn('day', date_format(col('date'), \"d\"))\n","\n","hm = hm[hm['year'] == 2020]\n","hm = hm[hm['month'] == 9]\n","hm = hm[hm['day'] == 22]\n","transaction.unpersist()\n","\n","# Prepare the dataset\n","hm = hm.groupby('customer_id', 'article_id').count()\n","hm.show(5)"]},{"cell_type":"code","execution_count":7,"id":"d6cbcd94","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 7:=====================================================>   (32 + 2) / 34]\r"]},{"name":"stdout","output_type":"stream","text":["(1592, 3)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["print((hm.count(), len(hm.columns)))"]},{"cell_type":"code","execution_count":8,"id":"f4163d70","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 29:=================================================>      (30 + 4) / 34]\r"]},{"name":"stdout","output_type":"stream","text":["Sparsity:  99.91%.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Count the total number of article in the dataset\n","numerator = hm.select(\"count\").count()\n","\n","# Count the number of distinct customerid and distinct articleid\n","num_users = hm.select(\"customer_id\").distinct().count()\n","num_articles = hm.select(\"article_id\").distinct().count()\n","\n","# Set the denominator equal to the number of customer multiplied by the number of articles\n","denominator = num_users * num_articles\n","\n","# Divide the numerator by the denominator\n","sparsity = (1.0 - (numerator *1.0)/denominator)*100\n","print(\"Sparsity: \", \"%.2f\" % sparsity + \"%.\")"]},{"cell_type":"code","execution_count":9,"id":"8fa72947","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 39:=================================================>      (30 + 4) / 34]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------+-----+\n","|         customer_id|count|\n","+--------------------+-----+\n","|af189ae7ead49625d...|    5|\n","|a88ade5b98f2bbd4d...|    3|\n","|17f39ee02b4dd5207...|    3|\n","|a3e49519308109be0...|    3|\n","|b3d8252651bfc39d7...|    3|\n","|02557f2324a3d792b...|    3|\n","|3bc6e152ae9934244...|    3|\n","|82f6ae6750bf405f3...|    3|\n","|54e8ebd39543b5a4d...|    3|\n","|cdced65c2f229cc01...|    3|\n","|c987d6ac4fef3ea1e...|    3|\n","|25f205769ce0472f2...|    3|\n","|dc1b173e541f8d3c1...|    3|\n","|ba06d797232ec40e0...|    3|\n","|1a42bca32c5816966...|    3|\n","|77f0df38f68e62211...|    3|\n","|92713e3aa7d55dd3d...|    3|\n","|a865b2486c390f9fe...|    3|\n","|64e77fb36ec90ef3b...|    3|\n","|7b3787571cdfa173e...|    3|\n","+--------------------+-----+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["userId_count = hm.groupBy(\"customer_id\").count().orderBy('count', ascending=False)\n","userId_count.show()"]},{"cell_type":"code","execution_count":10,"id":"715404a0","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 45:======================================================> (33 + 1) / 34]\r"]},{"name":"stdout","output_type":"stream","text":["+----------+-----+\n","|article_id|count|\n","+----------+-----+\n","| 791587001|    6|\n","| 787946002|    6|\n","| 573085028|    6|\n","| 886566001|    6|\n","| 929275001|    6|\n","| 866731001|    6|\n","| 915529005|    5|\n","| 898692006|    5|\n","| 915529003|    5|\n","| 714790020|    5|\n","| 930380001|    5|\n","| 924243002|    5|\n","| 923340001|    4|\n","| 905957007|    4|\n","| 896169002|    4|\n","| 714790028|    4|\n","| 863583001|    4|\n","| 788575002|    4|\n","| 903420001|    4|\n","| 909014001|    4|\n","+----------+-----+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["articleId_count = hm.groupBy(\"article_id\").count().orderBy('count', ascending=False)\n","articleId_count.show()"]},{"cell_type":"code","execution_count":11,"id":"1312e7e6","metadata":{},"outputs":[],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.recommendation import ALS"]},{"cell_type":"code","execution_count":12,"id":"e239d8c4","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 63:====================================================>   (32 + 2) / 34]\r"]},{"name":"stdout","output_type":"stream","text":["+--------------------+----------+-----+----------------+-----------------+\n","|         customer_id|article_id|count|article_id_index|customer_id_index|\n","+--------------------+----------+-----+----------------+-----------------+\n","|82be633d4ca5ea541...| 927172004|    1|          1180.0|            810.0|\n","|3ec69c320b6aced81...| 631536021|    1|           327.0|            490.0|\n","|a2be13b3998897084...| 828991003|    1|           136.0|            973.0|\n","|1b2867a6205a7a528...| 894788003|    1|           951.0|            292.0|\n","|d2f89ce024ac8d4fb...| 849738002|    1|           707.0|            130.0|\n","|6350568da716f096e...| 448509014|    1|            81.0|             69.0|\n","|91fdfb07f31100dd6...| 842360001|    1|           692.0|            896.0|\n","|0003e867a930d0d68...| 827487003|    1|           642.0|            151.0|\n","|2f03d37985cfef3cf...| 908584001|    1|           203.0|            393.0|\n","|b49647f84a99ced53...| 905660002|    1|          1027.0|           1044.0|\n","|5252a97cea20c3f4d...| 797892001|    1|           552.0|             58.0|\n","|c0247cf307c024f4c...| 829693002|    1|           651.0|           1108.0|\n","|4eebec4fcf4a1b177...| 923569002|    1|            74.0|            568.0|\n","|bcb0b95235855f64e...| 862272004|    1|           753.0|           1088.0|\n","|4cf8c9e9d3fa7729b...| 907951001|    1|          1053.0|            552.0|\n","|7f7b39c328670b435...| 706016001|    1|            14.0|            794.0|\n","|8f83268ae0e025b75...| 564358060|    1|           297.0|             99.0|\n","|260f3d4c121e6edfe...| 678942057|    1|           352.0|            349.0|\n","|8fad4a609a1b11e2f...| 924250001|    1|          1170.0|            886.0|\n","|083c246715671fbf8...| 893432005|    1|            24.0|            199.0|\n","+--------------------+----------+-----+----------------+-----------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.ml.feature import StringIndexer\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import col\n","indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in list(set(hm.columns)-set(['count'])) ]\n","pipeline = Pipeline(stages=indexer)\n","transformed = pipeline.fit(hm).transform(hm)\n","transformed.show()"]},{"cell_type":"code","execution_count":13,"id":"6d28d152","metadata":{},"outputs":[],"source":["(training,test)=transformed.randomSplit([0.8, 0.2])"]},{"cell_type":"code","execution_count":null,"id":"73c279cf","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.recommendation import ALS\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","\n","\n","#create ALS model\n","als=ALS(userCol=\"customer_id_index\",itemCol=\"article_id_index\",ratingCol=\"count\",coldStartStrategy=\"drop\",nonnegative=True)\n","\n","#tune model using ParamGridBuilder\n","param_grid = ParamGridBuilder()\\\n","            .addGrid(als.rank, [15,20,25])\\\n","            .addGrid(als.maxIter,[5,10,15])\\\n","            .addGrid(als.regParam,[0.09,0.14,0.19])\\\n","            .build()\n","#define evaluator as RMSE\n","evaluator = RegressionEvaluator(metricName = \"rmse\",labelCol = 'count', predictionCol = 'prediction')\n","\n","#Build cross validation using CrossValidator\n","cv = CrossValidator(estimator=als,estimatorParamMaps=param_grid, evaluator=evaluator,numFolds=3)\n","\n","\n","#Fit ALS model to training data\n","model = cv.fit(training)"]},{"cell_type":"code","execution_count":null,"id":"86aa6ae8","metadata":{},"outputs":[],"source":["als=ALS(maxIter=5,regParam=0.09,rank=25,userCol=\"customer_id_index\",itemCol=\"article_id_index\",ratingCol=\"count\",coldStartStrategy=\"drop\",nonnegative=True)\n"]},{"cell_type":"code","execution_count":null,"id":"3d02d6b0","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#Extract best model from the tuning exercise using ParamGridBuilder\n","best_model = model.bestModel\n","\n","#Generate predictions and evaluate using RMSE\n","predictions = best_model.transform(test)\n","rmse = evaluator.evaluate(predictions)"]},{"cell_type":"code","execution_count":null,"id":"6f553a9f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE =0.6909940669462347\n","**Best Model**\n","Rank : 25\n","MaxIter: 5\n","RegParam: 0.09\n"]}],"source":["#print evaluation metrics and model parameters\n","print(\"RMSE =\" + str(rmse))\n","print(\"**Best Model**\")\n","print(\"Rank : {}\".format(best_model.rank))\n","print(\"MaxIter: {}\".format(best_model._java_obj.parent().getMaxIter()))\n","print(\"RegParam: {}\".format(best_model._java_obj.parent().getRegParam()))"]},{"cell_type":"code","execution_count":null,"id":"2df0ca17","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyspark in /usr/lib/spark/python (3.1.3)\n","Collecting pyspark\n","  Using cached pyspark-3.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/miniconda3/lib/python3.8/site-packages (from pyspark) (0.10.9.7)\n","Installing collected packages: pyspark\n","  Attempting uninstall: pyspark\n","    Found existing installation: pyspark 3.1.3\n","    Can't uninstall 'pyspark'. No files were found to uninstall.\n","Successfully installed pyspark-3.4.0\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install --upgrade pyspark"]},{"cell_type":"code","execution_count":null,"id":"ba11b76a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: py4j in /opt/conda/miniconda3/lib/python3.8/site-packages (0.10.9.7)\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install --upgrade py4j"]},{"cell_type":"code","execution_count":null,"id":"2b896f92","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","    .appName(\"my-app\") \\\n","    .config(\"spark.driver.memory\", \"4g\") \\\n","    .config(\"spark.executor.memory\", \"4g\") \\\n","    .getOrCreate()\n"]},{"cell_type":"code","execution_count":null,"id":"4e9aeb03","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 9065:===================================================> (98 + 1) / 100]\r"]},{"name":"stdout","output_type":"stream","text":["+----------------+--------------------+\n","|article_id_index|     recommendations|\n","+----------------+--------------------+\n","|               1|[{545, 1.8978157}...|\n","|              12|[{545, 1.3193089}...|\n","|              22|[{1417, 0.9236878...|\n","|              26|[{8, 0.9273679}, ...|\n","|              27|[{75, 0.9286343},...|\n","|              28|[{68, 0.92859066}...|\n","|              31|[{36, 0.92532855}...|\n","|              34|[{1288, 0.9250935...|\n","|              44|[{79, 0.9222984},...|\n","|              47|[{545, 0.9665778}...|\n","+----------------+--------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["user_recs = best_model.recommendForAllItems(10)\n","user_recs.show(10)"]},{"cell_type":"code","execution_count":null,"id":"8a012b85","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"815e5683","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 9096:===================================================> (98 + 1) / 100]\r"]},{"name":"stdout","output_type":"stream","text":["+-----------------+--------------------+\n","|customer_id_index|     recommendations|\n","+-----------------+--------------------+\n","|                1|[{1135, 0.9607761...|\n","|               12|[{377, 0.92105657...|\n","|               22|[{1100, 0.947925}...|\n","|               26|[{825, 0.9317713}...|\n","|               27|[{1192, 0.97896},...|\n","|               28|[{241, 0.92162794...|\n","|               31|[{1135, 1.9058945...|\n","|               34|[{659, 0.94389564...|\n","|               44|[{435, 0.9251446}...|\n","|               47|[{558, 1.1301042}...|\n","+-----------------+--------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_recom = best_model.recommendForAllUsers(10)\n","df_recom.show(10)"]},{"cell_type":"code","execution_count":null,"id":"28b74f1f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----------------+--------------------+\n","|customer_id_index|    article_id_index|\n","+-----------------+--------------------+\n","|                1|[1135, 1192, 659,...|\n","|               12|[644, 865, 377, 8...|\n","|               22|[1100, 252, 82, 5...|\n","|               26|[825, 52, 987, 11...|\n","|               27|[1192, 825, 1135,...|\n","|               28|[241, 1135, 1192,...|\n","|               31|[1135, 11, 825, 6...|\n","|               34|[659, 215, 300, 1...|\n","|               44|[435, 699, 89, 36...|\n","|               47|[558, 1219, 1100,...|\n","+-----------------+--------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_recom = df_recom.select(\"customer_id_index\",\"recommendations.article_id_index\")\n","df_recom.show(10)\n","df_recom = df_recom.toPandas()"]},{"cell_type":"code","execution_count":null,"id":"72522f53","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id_index</th>\n","      <th>article_id_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>861</th>\n","      <td>0</td>\n","      <td>[129, 1132, 751, 638, 1135, 222, 1, 188, 313, ...</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[1135, 1192, 659, 259, 267, 825, 558, 170, 19,...</td>\n","    </tr>\n","    <tr>\n","      <th>862</th>\n","      <td>2</td>\n","      <td>[3, 715, 27, 6, 994, 393, 35, 214, 479, 337]</td>\n","    </tr>\n","    <tr>\n","      <th>288</th>\n","      <td>3</td>\n","      <td>[659, 1135, 701, 633, 1101, 124, 561, 392, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>577</th>\n","      <td>4</td>\n","      <td>[441, 957, 558, 368, 104, 237, 938, 737, 599, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>1414</td>\n","      <td>[1192, 1209, 825, 1, 1033, 217, 50, 12, 1110, ...</td>\n","    </tr>\n","    <tr>\n","      <th>285</th>\n","      <td>1415</td>\n","      <td>[659, 1074, 1135, 671, 1100, 145, 183, 546, 22...</td>\n","    </tr>\n","    <tr>\n","      <th>1139</th>\n","      <td>1416</td>\n","      <td>[1192, 586, 659, 1135, 825, 758, 1143, 532, 38...</td>\n","    </tr>\n","    <tr>\n","      <th>286</th>\n","      <td>1417</td>\n","      <td>[22, 1192, 1135, 659, 1210, 993, 164, 825, 110...</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>1418</td>\n","      <td>[825, 928, 659, 62, 18, 139, 924, 641, 639, 1128]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1153 rows × 2 columns</p>\n","</div>"],"text/plain":["      customer_id_index                                   article_id_index\n","861                   0  [129, 1132, 751, 638, 1135, 222, 1, 188, 313, ...\n","0                     1  [1135, 1192, 659, 259, 267, 825, 558, 170, 19,...\n","862                   2       [3, 715, 27, 6, 994, 393, 35, 214, 479, 337]\n","288                   3  [659, 1135, 701, 633, 1101, 124, 561, 392, 0, ...\n","577                   4  [441, 957, 558, 368, 104, 237, 938, 737, 599, ...\n","...                 ...                                                ...\n","860                1414  [1192, 1209, 825, 1, 1033, 217, 50, 12, 1110, ...\n","285                1415  [659, 1074, 1135, 671, 1100, 145, 183, 546, 22...\n","1139               1416  [1192, 586, 659, 1135, 825, 758, 1143, 532, 38...\n","286                1417  [22, 1192, 1135, 659, 1210, 993, 164, 825, 110...\n","287                1418  [825, 928, 659, 62, 18, 139, 924, 641, 639, 1128]\n","\n","[1153 rows x 2 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df_recom.sort_values('customer_id_index')"]},{"cell_type":"code","execution_count":null,"id":"a4a6c38d","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}